"""
ìµœì¢…
"""

# ---------------------------
# ì½˜ì†” ì¸ì½”ë”© ì˜¤ë¥˜ ë°©ì§€ ì„¤ì • (Windows)
# ---------------------------
import sys
sys.stdin.reconfigure(encoding='utf-8')
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

import os
os.environ["PYTHONIOENCODING"] = "utf-8"

# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pathlib
import subprocess
import time
from datetime import datetime
from collections import Counter
from statistics import mean

# ì¨ë“œíŒŒí‹°
import cv2
import numpy as np
import torch
import torch.nn.functional as F
from fastapi import FastAPI, UploadFile, File, HTTPException, Depends, status, Query, Request
from fastapi.responses import JSONResponse, Response
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy import create_engine, Column, Integer, String, JSON, LargeBinary, ForeignKey, DateTime, or_
from sqlalchemy.orm import sessionmaker, Session, declarative_base, relationship
from urllib.parse import quote_plus
from pyngrok import ngrok, conf
import requests
import uvicorn

# ---------------------------
# ngrok ì„¤ì •
# ---------------------------
NGROK_AUTH_TOKEN = "2jGzT5KrMCTO5lJZq68sIhvwo2N_41kScxnYWbstYACqQqjHS"
os.environ["NGROK_AUTH_TOKEN"] = NGROK_AUTH_TOKEN
ngrok.set_auth_token(NGROK_AUTH_TOKEN)
conf.get_default().encoding = "utf-8"  # ngrok ë¡œê·¸ ì¸ì½”ë”© ê°•ì œ ì„¤ì •

# ---------------------------
# MySQL ì„¤ì • (ë¡œì»¬)
# ---------------------------
db_user = "fastapi"
db_password = "Fastapi123@@"
db_host = "127.0.0.1"
db_port = 3306
db_name = "fastapi_test"

encoded_password = quote_plus(db_password)
DATABASE_URL = f"mysql+pymysql://{db_user}:{encoded_password}@{db_host}:{db_port}/{db_name}"

# ---------------------------
# DB ì—”ì§„ ë° ì„¸ì…˜ ìƒì„±
# ---------------------------
engine = create_engine(DATABASE_URL, echo=True)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# ---------------------------
# í…Œì´ë¸” ì •ì˜
# ---------------------------
class DetectionResult(Base):
    __tablename__ = "detection_results"
    id = Column(Integer, primary_key=True, index=True)
    main_image = Column(LargeBinary)
    # content:
    # {
    #   "total_leaves": int,
    #   "deficiency_prob": float,
    #   "model_accuracy": float (optional),
    #   "leaf_results":[{"label":str,"conf":float,"bbox":[x1,y1,x2,y2]}, ...]
    # }
    content = Column(JSON)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    crops = relationship("PostCrop", back_populates="post", cascade="all, delete-orphan")

class PostCrop(Base):
    __tablename__ = "post_crops"
    id = Column(Integer, primary_key=True, index=True)
    post_id = Column(Integer, ForeignKey("detection_results.id"))
    crop_image = Column(LargeBinary)
    order_index = Column(Integer)
    created_at = Column(DateTime, default=datetime.utcnow)
    post = relationship("DetectionResult", back_populates="crops")

class RecommendationInfo(Base):
    __tablename__ = "recommendation_info"
    id = Column(Integer, primary_key=True, index=True)
    nutrient = Column(String(50), nullable=False)       # "N","P","K","healthy"
    fertilizer = Column(JSON)                           # ["...", ...]
    prevention = Column(JSON)                           # ["...", ...]
    symptoms = Column(JSON)                             # ["...", ...]
    type_code = Column(String(16), unique=True, index=True)  # N/P/K/healthy (ìˆìœ¼ë©´ ì‚¬ìš©)

# í…Œì´ë¸” ì—†ìœ¼ë©´ ìƒì„±
Base.metadata.create_all(bind=engine)

# ---------------------------
# DB ì„¸ì…˜ ì˜ì¡´ì„±
# ---------------------------
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ---------------------------
# ëª¨ë¸ ë¡œë“œ
# ---------------------------
DETECT_WEIGHTS = "./leaf_detect.pt"
CLS_WEIGHTS    = "./lack_classify.pt"

print("ğŸ“¦ ëª¨ë¸ ë¡œë“œ ì¤‘...")
device = 'cuda' if torch.cuda.is_available() else 'cpu'

def load_yolov5_model(weights_path: str):
    """Windows í™˜ê²½ torch.hub + yolov5 ë¡œë”© ì´ìŠˆ ìš°íšŒ"""
    try:
        return torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path)
    except Exception as e1:
        try:
            _orig = pathlib.PosixPath
            pathlib.PosixPath = pathlib.WindowsPath
            m = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path, force_reload=True)
            pathlib.PosixPath = _orig
            return m
        except Exception as e2:
            raise RuntimeError(f"YOLOv5 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e1} / {e2}")

yolo_det = load_yolov5_model(DETECT_WEIGHTS)
cls_model = load_yolov5_model(CLS_WEIGHTS)

# íƒì§€ í•˜ì´í¼íŒŒë¼ë¯¸í„°(ê°€ëŠ¥í•˜ë©´ ì ìš©)
try:
    yolo_det.conf = 0.6
    yolo_det.iou  = 0.45
    yolo_det.max_det = 50
except Exception:
    pass

yolo_det.to(device).eval()
cls_model.to(device).eval()
cls_names = getattr(cls_model, 'names', None) or ['healthy','n','p','k']
print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# ---------------------------
# ë¶„ë¥˜ ì „ì²˜ë¦¬/ì¶”ë¡  ìœ í‹¸
# ---------------------------
def preprocess_for_cls(crop_bgr, size=224):
    rgb = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2RGB)
    img = cv2.resize(rgb, (size, size), interpolation=cv2.INTER_AREA)
    img = img.astype(np.float32) / 255.0
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    img = (img - mean) / std
    img = np.transpose(img, (2, 0, 1))
    t = torch.from_numpy(img).unsqueeze(0).contiguous().to(device=device, dtype=torch.float32)
    return t

@torch.no_grad()
def classify_crop(crop_bgr):
    x = preprocess_for_cls(crop_bgr, size=224)
    out = cls_model(x)
    probs = None
    if hasattr(out, 'probs'):
        p = out.probs[0] if isinstance(out.probs, list) else out.probs
        probs = p if torch.is_tensor(p) else torch.tensor(p)
    if probs is None:
        logits = out if torch.is_tensor(out) else getattr(out, 'logits', torch.as_tensor(out))
        if logits.ndim == 1:
            logits = logits.unsqueeze(0)
        probs = F.softmax(logits[0], dim=-1)
    probs_np = probs.float().detach().cpu().numpy()
    idx = int(np.argmax(probs_np))
    if isinstance(cls_names, dict):
        label = cls_names.get(idx, f"class_{idx}")
    else:
        label = cls_names[idx] if idx < len(cls_names) else f"class_{idx}"
    return label, float(probs_np[idx])

# ---------------------------
# FastAPI ì•± ì„¤ì •
# ---------------------------
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"]
)

# ---------------------------
# ì„œë²„ ìƒíƒœ í™•ì¸
# ---------------------------
@app.get("/health")
async def health_check():
    return {"status": "ok", "message": "Server is alive"}

# ---------------------------
# ê°ì§€ ë° DB ì €ì¥
# ---------------------------
@app.post("/detect")
async def detect(file: UploadFile = File(...), db: Session = Depends(get_db)):
    if not file.content_type or not file.content_type.startswith("image"):
        raise HTTPException(status.HTTP_400_BAD_REQUEST, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    image_bytes = await file.read()
    arr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    if img is None:
        raise HTTPException(status.HTTP_400_BAD_REQUEST, detail="ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")

    det = yolo_det(img, size=416)
    df = det.pandas().xyxy[0]

    crops = []
    for _, row in df.iterrows():
        x1, y1, x2, y2 = map(int, [row.xmin, row.ymin, row.xmax, row.ymax])
        crop = img[y1:y2, x1:x2]
        if crop.size == 0:
            continue
        label, conf = classify_crop(crop)
        ok, buf = cv2.imencode(".png", crop)
        if not ok:
            continue
        crops.append({
            "order_index": len(crops),
            "crop_blob": buf.tobytes(),
            "label": label,
            "conf": conf,
            "bbox": [x1, y1, x2, y2]
        })

    total = len(crops)
    lack_cnt = sum(1 for c in crops if str(c["label"]).lower() != "healthy")
    deficiency_prob = round((lack_cnt / total) * 100, 2) if total > 0 else 0.0

    # contentì— ëª¨ë¸ ì •í™•ë„ í•„ë“œ í¬í•¨(ì•± í‘œì‹œìš©)
    model_accuracy = 93.0  # í•„ìš” ì‹œ ì‹¤ì œ ê°’ìœ¼ë¡œ êµì²´
    db_main = DetectionResult(
        main_image=image_bytes,
        content={
            "total_leaves": total,
            "deficiency_prob": deficiency_prob,
            "model_accuracy": model_accuracy,
            "leaf_results": [
                {"label": c["label"], "conf": c["conf"], "bbox": c["bbox"]}
                for c in crops
            ]
        }
    )
    db.add(db_main)
    db.commit()
    db.refresh(db_main)

    crop_records = [
        PostCrop(post_id=db_main.id, crop_image=c["crop_blob"], order_index=c["order_index"])
        for c in crops
    ]
    if crop_records:
        db.add_all(crop_records)
        db.commit()

    return JSONResponse(content={
        "status": "success",
        "message": "íƒì§€/ë¶„ë¥˜ ì™„ë£Œ ë° DB ì €ì¥",
        "data": {
            "id": db_main.id,
            "total_leaves": total,
            "deficiency_prob": deficiency_prob,
            "detections": [
                {"label": c["label"], "conf": round(c["conf"], 4), "bbox": c["bbox"]}
                for c in crops
            ]
        }
    })

# ---------------------------
# ì•±ì—ì„œ í˜¸ì¶œí•  ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸
# ---------------------------
@app.post("/upload")
async def upload(file: UploadFile = File(...), db: Session = Depends(get_db)):
    return await detect(file=file, db=db)

# ---------------------------
# ìœ í‹¸: ì´ë¯¸ì§€ MIME ì¶”ì •, ì ˆëŒ€ URL êµ¬ì„±
# ---------------------------
def _guess_media_type(img_bytes: bytes) -> str:
    if not img_bytes or len(img_bytes) < 4:
        return "image/png"
    if img_bytes[0] == 0xFF and img_bytes[1] == 0xD8:
        return "image/jpeg"
    if img_bytes[0] == 0x89 and img_bytes[1] == 0x50 and img_bytes[2] == 0x4E and img_bytes[3] == 0x47:
        return "image/png"
    return "image/png"

def _weekday_kr(dt: datetime) -> str:
    return ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"][dt.weekday()]

def _major_deficiency(leaf_results):
    labels = [str(lr.get("label", "")).lower() for lr in leaf_results]
    lack_only = [l for l in labels if l and l != "healthy"]
    if not lack_only:
        return "HEALTHY"
    return Counter(lack_only).most_common(1)[0][0].upper()

def _abs_url(path: str, public_url: str | None, request: Request) -> str:
    if path.startswith("http://") or path.startswith("https://"):
        return path
    if public_url:
        return f"{public_url.rstrip('/')}{path}"
    base = str(request.base_url).rstrip("/")
    return f"{base}{path}"

# ---------------------------
# DB ê²°ê³¼ ì¡°íšŒ (ë¦¬ìŠ¤íŠ¸)
# ---------------------------
@app.get("/results")
async def get_results(db: Session = Depends(get_db), request: Request = None):
    rows = db.query(DetectionResult).order_by(DetectionResult.id.desc()).all()
    return JSONResponse(content={
        "status": "success",
        "results": [
            {
                "id": r.id,
                "created_at": r.created_at.strftime("%Y-%m-%d %H:%M:%S"),
                "updated_at": r.updated_at.strftime("%Y-%m-%d %H:%M:%S"),
                "content": r.content,
                "crop_count": len(r.crops),
                "main_image_url": _abs_url(f"/image/{r.id}", public_url, request) if request else f"/image/{r.id}"
            } for r in rows
        ]
    })

# ---------------------------
# ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ì‘ë‹µ
# ---------------------------
@app.get("/image/{post_id}")
async def get_main_image(post_id: int, db: Session = Depends(get_db)):
    r = db.get(DetectionResult, post_id)
    if not r or not r.main_image:
        raise HTTPException(404, "ì´ë¯¸ì§€ ì—†ìŒ")
    return Response(content=r.main_image, media_type=_guess_media_type(r.main_image))

@app.get("/crop/{post_id}")
async def get_crop_image(post_id: int, index: int = Query(0, ge=0), db: Session = Depends(get_db)):
    r = db.get(DetectionResult, post_id)
    if not r or not r.crops or index >= len(r.crops):
        raise HTTPException(404, "í¬ë¡­ ì´ë¯¸ì§€ ì—†ìŒ")
    blob = sorted(r.crops, key=lambda c: c.order_index)[index].crop_image
    return Response(content=blob, media_type=_guess_media_type(blob))

# ---------------------------
# ë³´ê³ ì„œ(í™”ë©´ìš©) JSON
# ---------------------------
@app.get("/report/{post_id}")
async def get_report(post_id: int, request: Request, db: Session = Depends(get_db)):
    r = db.get(DetectionResult, post_id)
    if not r:
        raise HTTPException(404, "ê²°ê³¼ ì—†ìŒ")

    content = r.content or {}
    leaf_results = content.get("leaf_results", [])
    total_objects = int(content.get("total_leaves", len(leaf_results)))
    total_detected = sum(1 for lr in leaf_results if str(lr.get("label","")).lower() != "healthy")
    deficiency_prob = float(content.get("deficiency_prob", round(100 * total_detected / max(total_objects,1), 2)))

    # accuracy: contentì— ìˆìœ¼ë©´ ìš°ì„ , ì—†ìœ¼ë©´ í‰ê·  confidence(%)ë¡œ ê³„ì‚°
    accuracy = float(content.get("model_accuracy", 0.0))
    if not accuracy:
        confs = [float(lr.get("conf", 0.0)) for lr in leaf_results if isinstance(lr, dict)]
        accuracy = round(mean(confs) * 100, 1) if confs else 0.0

    # ì´ë²ˆ ê²°ê³¼ì˜ ì£¼ìš” ê²°í• ì›ì†Œ
    def_type = _major_deficiency(leaf_results)  # N/P/K/HEALTHY

    # recommendation_info: type_code ë˜ëŠ” nutrientë¡œ ì¡°íšŒ
    rec = None
    if def_type in ("N","P","K","HEALTHY"):
        rec = db.query(RecommendationInfo).filter(
            or_(RecommendationInfo.type_code == def_type, RecommendationInfo.nutrient == def_type)
        ).first()

    # ë‚ ì§œ(ìƒì„±ì¼)
    now = r.created_at or datetime.utcnow()
    date_str = f"{now.year}ë…„ {now.month}ì›” {now.day}ì¼({_weekday_kr(now)})"

    # í¬ë¡­ URL(ìµœëŒ€ 5ê°œ)
    crop_urls = [_abs_url(f"/crop/{r.id}?index={i}", public_url, request) for i in range(min(len(r.crops), 5))]

    payload = {
        "date": date_str,
        "deficiency_type": def_type,                       # â† í´ë¼ê°€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        "deficiency_prob": deficiency_prob,
        "total_detected": total_detected,
        "total_objects": total_objects,
        "main_image_url": _abs_url(f"/image/{r.id}", public_url, request),
        "crop_image_urls": crop_urls,

        "accuracy": accuracy,                              # â† íƒ‘ë ˆë²¨ accuracy
        "metrics": { "map_05": None, "precision": None, "recall": None, "f1": None },

        # ì´ë²ˆ ê²°ê³¼ì˜ íƒ€ì…(def_type)ì— ë§ì¶˜ ì¶”ì²œ/ì˜ˆë°©/ì¦ìƒ
        "fertilizer_recommend": (rec.fertilizer if rec and rec.fertilizer else []),
        "prevention": (rec.prevention if rec and rec.prevention else []),
        "symptoms": (rec.symptoms if rec and rec.symptoms else []),

        "detections": leaf_results
    }
    return JSONResponse(content={"status": "success", "report": payload})

@app.get("/report/latest")
async def get_latest_report(request: Request, db: Session = Depends(get_db)):
    latest = db.query(DetectionResult).order_by(DetectionResult.id.desc()).first()
    if not latest:
        raise HTTPException(404, "ìµœê·¼ ê²°ê³¼ ì—†ìŒ")
    return await get_report(latest.id, request, db)

# ---------------------------
# (ì„ íƒ) ìµœì‹  1ê±´ ê°„ë‹¨ ìš”ì•½
# ---------------------------
@app.get("/posts/latest")
def get_latest_post(db: Session = Depends(get_db), request: Request = None):
    r = db.query(DetectionResult).order_by(DetectionResult.created_at.desc()).first()
    if not r:
        return {"status": "empty", "result": None}

    leaf_results = (r.content or {}).get("leaf_results", [])
    labels = [str(x.get("label","")).lower() for x in leaf_results if x.get("label")]
    lack_labels = [l for l in labels if l != "healthy"]
    top_lack = Counter(lack_labels).most_common(1)[0][0].upper() if lack_labels else "N/A"

    rec = None
    if top_lack not in ("N/A", "", None):
        rec = db.query(RecommendationInfo).filter(
            or_(RecommendationInfo.type_code == top_lack, RecommendationInfo.nutrient == top_lack)
        ).first()

    result = {
        "id": r.id,
        "created_at": r.created_at.strftime("%Y-%m-%d %H:%M:%S"),
        "deficiency_prob": (r.content or {}).get("deficiency_prob", 0),
        "deficiency_type": top_lack,
        "total_detected": len(lack_labels),
        "total_objects": (r.content or {}).get("total_leaves", 0),
        "main_image_url": _abs_url(f"/image/{r.id}", public_url, request) if request else f"/image/{r.id}",
        "crops": [
            {
                "id": c.id,
                "order_index": c.order_index,
                "url": _abs_url(f"/crop/{r.id}?index={c.order_index}", public_url, request) if request else f"/crop/{r.id}?index={c.order_index}"
            }
            for c in sorted(r.crops, key=lambda x: x.order_index or 0)
        ],
        "recommend": {
            "fertilizers": (rec.fertilizer if rec and rec.fertilizer else []),
            "preventions": (rec.prevention if rec and rec.prevention else []),
        }
    }
    return {"status": "success", "result": result}

# ---------------------------
# ngrok ì‹¤í–‰
# ---------------------------
public_url = None
try:
    subprocess.Popen(["ngrok", "http", "8000"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    time.sleep(3)
    tunnel_info = requests.get("http://127.0.0.1:4040/api/tunnels").json()
    public_url = tunnel_info["tunnels"][0]["public_url"]
    print("ê³µìš© URL:", public_url)
except Exception as e:
    print("ngrok URLì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤:", e)
    public_url = None

# ---------------------------
# ì„œë²„ ì‹¤í–‰
# ---------------------------
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
